{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos librerias\n",
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = open('comentarios_atencion_cliente sin_etiquetas.csv','r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo1 = \" \".join(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo2 = archivo1.replace(\";\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo3 = archivo2.replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo4 = archivo3.strip(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo5 = archivo4.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo6 = archivo5.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"spanish\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo7 = word_tokenize(archivo5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo8 = filter(lambda x: x not in stop_words, archivo7) #Quitamos Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(archivo8) #Convertimos a lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seguimos limpiando caracteres que son menores a 3 los quitamos\n",
    "c=[]\n",
    "for i in a:\n",
    "    if len(i)>=3:\n",
    "        c.append(i)\n",
    "b = \" \".join(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = word2vec.Text8Corpus('text8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(sentences, size=200,min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('text8_pc4.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('text8_pc4.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFV(document):#document es una cadena de palabras\n",
    "    \n",
    "    words=document.split()#lista de palabras separadas\n",
    "    s=np.zeros(200)\n",
    "    k=0#contador\n",
    "    for w in words:#para cada palabra que esta dentro de words\n",
    "        if w in model.wv.vocab:#si la palabra estsa la encuentra y la suma\n",
    "            s=s+model[w]\n",
    "            k=k+1\n",
    "    \n",
    "    return s/k#retorna el promedio el vector caracteristico del documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos la funcion getFV con la lista de palabras\n",
    "getFV(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#archivo_final = open(\"data.txt\", \"w\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un archivo que almacenará la lista de palabras limpias del conjunto de comentarios\n",
    "with open(\"data.txt\", 'w', encoding ='utf8') as f:  \n",
    "            f.write(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos que el archivo fue guardado correctamente\n",
    "archivoprueba = open(\"data.txt\", 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un sentences el cual será usado en el modelo para reentrenarlo\n",
    "sentences2 = word2vec.Text8Corpus(\"data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anadimos el Sentences al modelo\n",
    "model.build_vocab(sentences2,update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamos el modelo con el nuevo sentences, pues contiene datos nuevos en ESP para poder clasificar\n",
    "model.train(sentences2, total_examples=model.corpus_count, epochs=model.iter) #reentrenamos el modelo con las palabras añadidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificamos que el modelo esta funcionando correctamente. Esto se hace con lo siguiente:\n",
    "model.most_similar(['servicio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una lista que contendra lista de comentarios limpios\n",
    "m = []\n",
    "for i in archivo:\n",
    "    a = str(i)\n",
    "    b=a.replace(\";\",\"\")\n",
    "    c = b.replace(\"\\n\",\"\")\n",
    "    d = c.strip(' ')\n",
    "    e = d.replace(\"  \", \" \")\n",
    "    f = e.lower()\n",
    "    m.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una lista que contendra los arrays caracteristicos usando la funcion getFV\n",
    "X=[]\n",
    "for w in m:\n",
    "    a=getFV(w)\n",
    "    X.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)#Verificamos el tamaño de la lista de vectores caracteristicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos usar la siguiente operacion para poder obtener la lista limpia sin NaN\n",
    "#Si cambiamos if not por if podemos obtener solo la lista de NaN\n",
    "#No se uso esta operacion pues para terminos de analisis de Machine Learnin era necesario mantener las listas con\n",
    "#Archivos NaN\n",
    "#import math\n",
    "#res2 = [t for t in X if not any(isinstance(n, float) and math.isnan(n) for n in t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpiamos la lista de vectores caracteristicos pues hay datos que al no encontralos los vuelve vectores NaN\n",
    "#Esto lo hacemos con\n",
    "b = np.where(np.isnan(X), 0, X)\n",
    "#aqui encuentra los nan y los reemplaza por ceros. Cuestion que no sesga mucho pues solo hemos identificado que son 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificamos que la nueva lista limpia tiene el mismo tamaño\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)#Verificamos nuevamente el tamaño de las listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la libreria de KMeans \n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos KMeans de 2 K para b\n",
    "est = KMeans(2)\n",
    "est.fit (b)\n",
    "y_mean=est.predict(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean#es el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrimos el archivo de positivos para verificar el Accuracy\n",
    "archivoPOSI = open('Positive.csv','r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una lista de los comentarios positivos\n",
    "POSI = []\n",
    "for i in archivoPOSI:\n",
    "    g = str(i)\n",
    "    h = g.replace(\";\",\"\")\n",
    "    i = h.replace(\"\\n\",\"\")\n",
    "    j = i.strip(' ')\n",
    "    k = j.replace(\"  \", \" \")\n",
    "    l = k.lower()\n",
    "    POSI.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando getFV appendamos los vectores caracteristicos en una lista P de positivos\n",
    "P=[]\n",
    "t=0\n",
    "for w in POSI:\n",
    "    a=getFV(w)\n",
    "    P.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpiamos la lista y convertimos los NaN en Ceros\n",
    "p_ = np.where(np.isnan(P), 0, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos KMeans para la lista p_ la cual contiene los vectores caracteristicos de los comentarios positivos\n",
    "estp = KMeans(2)\n",
    "estp.fit (p_)\n",
    "y_meanp=estp.predict(p_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_meanp # POSITIVOS K MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hallamos el Accuracy de los positivos usando el algoritmo KMeans\n",
    "upk=0\n",
    "for i in y_meanp:\n",
    "    if i == 1:\n",
    "        upk=upk+1\n",
    "print (upk/(len(y_meanp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrimos el archivo de negativos para verificar el Accuracy\n",
    "archivoNEGA = open('Negative.csv','r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una lista de los comentarios positivos y la limpiamos\n",
    "NEGA = []\n",
    "for i in archivoNEGA:\n",
    "    g = str(i)\n",
    "    h = g.replace(\";\",\"\")\n",
    "    i = h.replace(\"\\n\",\"\")\n",
    "    j = i.strip(' ')\n",
    "    k = j.replace(\"  \", \" \")\n",
    "    l = k.lower()\n",
    "    NEGA.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando getFV appendamos los vectores caracteristicos en una lista P de negativos\n",
    "N=[]\n",
    "for w in NEGA:\n",
    "    a=getFV(w)\n",
    "    N.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpiamos la lista n y convertimos los NaN en Ceros\n",
    "n_ = np.where(np.isnan(N), 0, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hallamos el Accuracy de los negativos usando el algoritmo KMeans\n",
    "estn = KMeans(2)\n",
    "estn.fit (n_)\n",
    "y_meann=estn.predict(n_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_meann #NEGATIVOS K MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando getFV appendamos los vectores caracteristicos en una lista P de negativos\n",
    "unk=0\n",
    "for i in y_meann:\n",
    "    if i == 1:\n",
    "        unk=unk+1\n",
    "print (unk/(len(y_meann)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrimos el csv etiquetado\n",
    "archivoSVM = open('label-comments_1400.csv','r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la libreria pandas. Creamos el dataframe\n",
    "import pandas as pd\n",
    "df = pd.read_csv('label-comments_1400.csv', delimiter = ';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos data frame con solo las columnas necesarias solo para ser ordenados\n",
    "df2 = df.drop(columns=[2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas = df2[0]#data frame de solo las etiquetas\n",
    "comments = df2[1]#data frame de solo los comentarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la lista para limpiarla\n",
    "c_c = []\n",
    "for i in comments:\n",
    "    g = str(i)\n",
    "    h = g.replace(\";\",\"\")\n",
    "    i = h.replace(\"\\n\",\"\")\n",
    "    j = i.strip(' ')\n",
    "    k = j.replace(\"  \", \" \")\n",
    "    l = k.lower()\n",
    "    c_c.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la lista que contendra los vectores caracteristicos de todos los comentarios\n",
    "co_v=[]\n",
    "for w in c_c:\n",
    "    a=getFV(w)\n",
    "    co_v.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpiamos la lista de los NaN y lo convertimos en ceros\n",
    "d=np.where(np.isnan(co_v), 0, co_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algoritmo de Support Vector Machine\n",
    "from sklearn import svm\n",
    "clasificador = svm.SVC(gamma=0.00001,C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos el clasificador SVM donde d es la lista de FV de los comentarios y etiquetas, las etiquetas\n",
    "clasificador.fit(d,etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predNEGAS = clasificador.predict(n_) #NEGATIVOS SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predNEGAS #Imprimimos el array de negativos con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hallamos el Accuracy de los negativos con SVM\n",
    "un=0\n",
    "for i in Y_predNEGAS:\n",
    "    if i == 1:\n",
    "        un=un+1\n",
    "print (un/(len(Y_predNEGAS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predPOSI = clasificador.predict(p_) #POSITIVOS SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predPOSI #Imprimimos el array de Positivos con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hallamos el Accuracy de los negativos con SVM\n",
    "up=0\n",
    "for i in Y_predPOSI:\n",
    "    if i == 1:\n",
    "        up=up+1\n",
    "print (up/(len(Y_predPOSI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
